{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Bootcamp -  BankNote.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPIo+gq/sOfpj1YT6sfAXfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Camicb/practice/blob/main/Deep_Learning_Bootcamp_BankNote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWC3CZ-WuEvX"
      },
      "source": [
        "# 1. Introduction\r\n",
        "## Context\r\n",
        "Banknotes are one of the most important assets of a country. Some miscreants introduce fake notes which bear a resemblance to original note to create discrepancies of the money in the financial market. It is difficult for humans to tell true and fake banknotes apart especially because they have a lot of similar features.\r\n",
        "\r\n",
        "## Motivation \r\n",
        "Despite a decrease in the use of currency due to the recent growth in the use of electronic transactions, cash transactions remain very important in the global market. Banknotes are used to carry out financial activities. To continue with smooth cash transactions, entry of forged banknotes in circulation should be preserved. There has been a drastic increase in the rate of fake notes in the market. Fake money is an imitation of the genuine notes and is created illegally for various motives. These fake notes are created in all denominations which brings the financial market of the country to a low level. The various advancements in the field of scanners and copy machines have led the miscreants to create copies of banknotes. It is difficult for human-eye to recognize a fake note because they are created with great accuracy to look alike a genuine note. Security aspects of banknotes have to be considered and security features are to be introduced to mitigate fake currency. Hence, there is a dire need in banks and ATM machines to implement a system that classifies a note as genuine or fake.\r\n",
        "\r\n",
        "[Source of Information: A research paper on Analysis of Banknote Authentication System using Machine Learning Techniques by Sumeet Shahani, Aisa Jagiasi and Priya RL at International Journal of Computer Applications (0975 – 8887) Volume 179 – No.20, February 2018]\r\n",
        "\r\n",
        "## Objective\r\n",
        "Being a Data Science Enthusiast, you committed yourself to use the power of Data Science and come up with an efficient model that accurately predicts if a note is genuine or not.\r\n",
        "\r\n",
        "##About the Data\r\n",
        "Data were extracted from images that were taken for the evaluation of an authentication procedure for banknotes. Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object grey-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool was used to extract features from images.\r\n",
        "\r\n",
        "##Data Description\r\n",
        "The dataset is downloaded from the UCI Machine Learning Repository.\r\n",
        "* VWTI: Variance of Wavelet Transformed Image\r\n",
        "* SWTI: Skewness of Wavelet Transformed Image\r\n",
        "* CWTI: Curtosis of Wavelet Transformed Image\r\n",
        "* EI: Entropy of Image\r\n",
        "* Class: Class (1: genuine, 0: forged)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJOj038TvoMt"
      },
      "source": [
        "#2. Importing libraries and loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3p8namft0_x"
      },
      "source": [
        "import tensorflow as tf                      \r\n",
        "import numpy as np                            \r\n",
        "import matplotlib.pyplot as plt               \r\n",
        "%matplotlib inline\r\n",
        "import pandas as pd\r\n",
        "from tensorflow import keras \r\n",
        "from tensorflow.keras import Sequential \r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toY19yXFxPN9"
      },
      "source": [
        "#training data\r\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/training_set_label.csv\" ) \r\n",
        "#test data\r\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/bank_note_data/testing_set_label.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAEOkDDew2o7"
      },
      "source": [
        "#3.Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlqkGUIPx3RF"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T551H7y5UGw"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBenmq5LyBfj"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_62Xehl-5ahj"
      },
      "source": [
        "test_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezJxUToOyp_j"
      },
      "source": [
        "train['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRyuRobryphR"
      },
      "source": [
        "# Spliting training data into a new training and validation datasets\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X=train.drop(\"Class\",axis=1)\r\n",
        "y=train.Class\r\n",
        "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.15,random_state=1, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i889GLFtzS9c"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX7abln_0I4s"
      },
      "source": [
        "#4. Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPnUBgA1zTgo"
      },
      "source": [
        "# Building the model\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))   \r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1isnuqW03lo"
      },
      "source": [
        "# Compiling the model\r\n",
        "model.compile(loss='binary_crossentropy', optimizer= 'adam' , metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgPxPYVP2X9l"
      },
      "source": [
        "# Fitting the model\r\n",
        "history = model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekY1mPP434Ua"
      },
      "source": [
        "# Evaluating the model\r\n",
        "model.evaluate(X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2bZrbQc4HHm"
      },
      "source": [
        "# Model accuracy \r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Model Accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['Train', 'Validation'])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM1q8Uou4T7o"
      },
      "source": [
        "# Model Loss\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Model Loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['Train', 'Validation'])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcrcg0Y142pL"
      },
      "source": [
        "# Predictions\r\n",
        "test=np.array(test_data)\r\n",
        "predictions=(model.predict_classes(test)>0.5).astype(\"int32\")\r\n",
        "\r\n",
        "res = pd.DataFrame(predictions) \r\n",
        "res.index = test_data.index\r\n",
        "res.columns = ['prediction']\r\n",
        " \r\n",
        "# To download the csv file locally\r\n",
        "from google.colab import files\r\n",
        "res.to_csv('prediction_results.csv', index=False)         \r\n",
        "files.download('prediction_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
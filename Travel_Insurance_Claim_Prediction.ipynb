{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Travel Insurance Claim Prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7tp4W7wvTbhebbaGPxj8I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Camicb/practice/blob/main/Travel_Insurance_Claim_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPnvvQ9tZyPH"
      },
      "source": [
        "#**Travel Insurance Claim Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a16dx2WOUHde"
      },
      "source": [
        "#1. Introduction\r\n",
        "\r\n",
        "Many companies selling tickets or travel packages, give consumers the option to purchase travel insurance, also known as travelers insurance. Travel insurance is a type of insurance that covers the costs and losses associated with traveling. It is useful protection for those traveling domestically or abroad.\r\n",
        "Some travel policies cover damage to personal property, rented equipment, such as rental cars, or even the cost of paying a ransom. \r\n",
        "\r\n",
        "The objective of this project is to create a machine learning model for a insurance company to predict if the insurance buyer will claim their travel insurance or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cHgFNumS2ZS"
      },
      "source": [
        "#2. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_4HFTmFzKjD"
      },
      "source": [
        "#!pip install -U imbalanced-learn\r\n",
        "#!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip \r\n",
        "#!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmitorvNUF2Q"
      },
      "source": [
        "#Importing libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "%matplotlib inline \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import missingno as msno \r\n",
        "from pandas_profiling import ProfileReport\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from IPython.core.interactiveshell import InteractiveShell\r\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
        "from sklearn import set_config\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from imblearn.over_sampling import SMOTE\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5LlRwh2U4aB"
      },
      "source": [
        "#3. Exploratory Data Analysis\r\n",
        "##3.1 About the data\r\n",
        "There are 11 columns in the dataset:\r\n",
        "*   **Duration:** Travel duration\r\n",
        "*   **Destination:** Travel destination (country)\r\n",
        "*   **Agency:** Agency Name\r\n",
        "*   **Agency Type:** Travel Agency or Airlines \r\n",
        "*   **Commission (in value):** Commission on the insurance\r\n",
        "*   **Age:** Age of the insurance buyer\r\n",
        "*   **Gender:** Gender of the insurance buyer\r\n",
        "*   **Distribution Channel:** offline/online\r\n",
        "*   **Product Name:** Name of the insurance plan\r\n",
        "*   **Net Sales:** Net sales\r\n",
        "*   **Claim:** If the insurance is claimed or not (the target variable), 0 = not claimed, 1 = claimed\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOwmzlveTfk0"
      },
      "source": [
        "# Load the provided data into a pandas data frame \r\n",
        "ins = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/travel_insurance/Training_set_label.csv\" ) # training data\r\n",
        "test_ins = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/travel_insurance/Testing_set_label.csv') # testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kh-mylaMyJ"
      },
      "source": [
        "## 3.2 Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZcqTUqi5uYB"
      },
      "source": [
        "ins.head()\r\n",
        "ins.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEpeL2qTCgIB"
      },
      "source": [
        "test_ins.head()\r\n",
        "test_ins.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOLGx8ROUTNO"
      },
      "source": [
        "The variable Claim is treated as numerical in the training dataset, so it will be transformed into a categorical one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAcbe8fdaAar"
      },
      "source": [
        "# Statistic report\r\n",
        "profile = ProfileReport(ins, html={'style': {'full_width': True, 'primary_color': '#30b6c2'}},  samples=None, missing_diagrams=None, interactions=None)\r\n",
        "profile.to_file(\"report.html\")\r\n",
        "profile.to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8blkDtSpECQ"
      },
      "source": [
        "# Visualization of missing values \r\n",
        "msno.matrix(ins, figsize=(10,5), fontsize=10, color=(0.0, 0.75, 0.75)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELHCcXqctB9u"
      },
      "source": [
        "Since 'Gender' has too many missing values and the 'Distribution Channel' is highly correlated to others variables and presents imbalanced classes, the entire columns will be removed. Then, the training data will be splited into a new training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alFAseRFr0xq"
      },
      "source": [
        "# Selecting the variables\r\n",
        "X=ins.drop(['Gender', 'Distribution Channel', 'Claim'], axis=1) \r\n",
        "y=ins['Claim']\r\n",
        "\r\n",
        "#Spliting the data with stratification into training and test sets \r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o_F7qQqr0rG"
      },
      "source": [
        "X_train.head()\r\n",
        "X_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_LkprMiEUrk"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BORUHz10aRd9"
      },
      "source": [
        "# 4. Data wrangling and Feature enginnering\r\n",
        "\r\n",
        "Changes in the testing data are executed in order to maintain a consistent shape with the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL1gqryIxkdN"
      },
      "source": [
        "pd.set_option('mode.chained_assignment',None) # no warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ7v1f8WS7Zo"
      },
      "source": [
        "4.1 Agency \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkVv6FplecyX"
      },
      "source": [
        "# Replacing the agencies with a frequency smaller than 5% to 'Other' \r\n",
        "Agencies=X_train.loc[:,'Agency'].value_counts(normalize=True)*100\r\n",
        "Agencies=list(Agencies[Agencies < 5].index)\r\n",
        "\r\n",
        "X_train.loc[:,'Agency']=X_train.loc[:,'Agency'].apply(lambda i: 'Other' if i in Agencies else i)\r\n",
        "X_test.loc[:,'Agency']=X_test.loc[:,'Agency'].apply(lambda i: 'Other' if i in Agencies else i) \r\n",
        "\r\n",
        "sns.histplot(data=X_train, x='Agency', color='c', stat='probability')\r\n",
        "plt.xticks(rotation='vertical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k3PE3LITDpD"
      },
      "source": [
        "4.2 Product Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow7-bxyxTDPP"
      },
      "source": [
        "# Replacing the products with a frequency smaller than 5% to 'Other Plan'\r\n",
        "Products=X_train.loc[:, 'Product Name'].value_counts(normalize=True)*100\r\n",
        "Products=list(Products[Products < 5].index)\r\n",
        "\r\n",
        "X_train['Product Name']=X_train['Product Name'].apply(lambda i: 'Other Plan' if i in Products else i)\r\n",
        "X_test['Product Name']=X_test['Product Name'].apply(lambda i: 'Other Plan' if i in Products else i)\r\n",
        "\r\n",
        "sns.histplot(data=X_train, x='Product Name', color='c', stat='probability')\r\n",
        "plt.xticks(rotation='vertical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBayiUJImcVT"
      },
      "source": [
        "4.3 Duration and Age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbk6XBFambby"
      },
      "source": [
        "# Transforming the values equal or smaller than zero for Duration and equal to 118 for Age for being clearly outliers.\r\n",
        "X_train['Duration']= X_train.loc[:, 'Duration'].apply(lambda i: np.nan if i < 1 else i)\r\n",
        "X_train['Duration'].isnull().value_counts(normalize=True)*100\r\n",
        "print('---')\r\n",
        "X_train['Age']= X_train.loc[:,'Age'].apply(lambda i: np.nan if i == 118 else i)\r\n",
        "X_train['Age'].isnull().value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqe8-JzapMv8"
      },
      "source": [
        "# Imputing NaN values\r\n",
        "#imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\r\n",
        "#X_train['Age'] = imputer.fit_transform(X_train[['Age']]).ravel()\r\n",
        "#X_train['Duration'] = imputer.fit_transform(X_train[['Duration']]).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI7Hu39Nw2nI"
      },
      "source": [
        "4.4 Destination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSE5eVAlw2E7"
      },
      "source": [
        "# Replacing the Destinations with a frequency smaller than 1% to 'OTHER'\r\n",
        "Destination=X_train.loc[:, 'Destination'].value_counts(normalize=True)*100\r\n",
        "Destination=list(Destination[Destination > 1].index)\r\n",
        "\r\n",
        "X_train['Destination']=X_train['Destination'].apply(lambda i: 'OTHER' if i not in Destination else i)\r\n",
        "X_test['Destination']=X_test['Destination'].apply(lambda i: 'OTHER' if i not in Destination else i)\r\n",
        "\r\n",
        "sns.histplot(data=X_train, x='Destination', color='c', stat='probability')\r\n",
        "plt.xticks(rotation='vertical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ixFzzdMEKL"
      },
      "source": [
        "4.5 Total sales : Net Sales and Commision (in  value)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w77aJ6POLyb2"
      },
      "source": [
        "# Adding both values since 55% of the commision values are zero\r\n",
        "X_train['Total sales']= X_train['Commision (in value)'] + X_train['Net Sales']\r\n",
        "X_test['Total sales']= X_test['Commision (in value)'] + X_test['Net Sales']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lujs9lKAYM-t"
      },
      "source": [
        "# Droping columns for being highly correlated now\r\n",
        "X_train=X_train.drop(columns=['Commision (in value)','Net Sales'], axis=1)\r\n",
        "X_test=X_test.drop(columns=['Commision (in value)','Net Sales'], axis=1)\r\n",
        "X_train.head()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHxiFGHHqJ9E"
      },
      "source": [
        "# Encoding the categorical variables with one hot encoding\r\n",
        "#]X_train=pd.get_dummies(X_train, columns=['Agency','Agency Type','Product Name','Destination'])  \r\n",
        "#X_test=pd.get_dummies(X_test, columns=['Agency','Agency Type','Product Name','Destination'])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngCzFrW4iYPZ"
      },
      "source": [
        "# SMOTE-oversampling the minority class in the target variable\r\n",
        "#sm = SMOTE(random_state = 25, sampling_strategy = 0.5)\r\n",
        "#X_train, y_train= sm.fit_sample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUfQ4nnQ2UfB"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rft8um0LapAY"
      },
      "source": [
        "# Checking the shape of the data for modeling\r\n",
        "X_train.shape\r\n",
        "y_train.shape\r\n",
        "X_test.shape\r\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLucz6_O84I5"
      },
      "source": [
        "# Choosing a model with pycaret \r\n",
        "from pycaret.classification import *\r\n",
        "\r\n",
        "train=pd.concat([X_train, y_train], axis=1)\r\n",
        "test=pd.concat([X_test, y_test], axis=1) #validation data\r\n",
        "\r\n",
        "clf=setup(train, target='Claim', test_data=test, \r\n",
        "          normalize=True, \r\n",
        "          fix_imbalance=True,\r\n",
        "          feature_selection=True,\r\n",
        "          feature_selection_threshold=0.9, \r\n",
        "          feature_selection_method='boruta')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3LWRYt-B71C"
      },
      "source": [
        "model=compare_models(sort='F1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl26drDQm4D7"
      },
      "source": [
        "#from sklearn.feature_selection import SelectFromModel\r\n",
        "#from sklearn.metrics import accuracy_score, f1_score\r\n",
        "#from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "#model = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\r\n",
        "#y_pred = model.predict(X_test)\r\n",
        "#ac = accuracy_score(y_test, y_pred)\r\n",
        "#fscore = f1_score(y_test ,y_pred)\r\n",
        "\r\n",
        "#print(\"Baseline Model Accuracy:\", ac)\r\n",
        "#print(\"Baseline Model F1 Score:\", fscore*100)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}